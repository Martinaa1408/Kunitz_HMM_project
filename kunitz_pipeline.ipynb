{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Kunitz Domain Detection Using Profile Hidden Markov Models (HMM)\n",
    "\n",
    "This notebook implements a bioinformatics pipeline to identify the Kunitz-type protease inhibitor domain (PF00014) in protein sequences using HMM-based detection.\n",
    "\n",
    "We will:\n",
    "- Collect and preprocess positive and negative datasets.\n",
    "- Reduce redundancy using CD-HIT and extract structural alignments from PDB.\n",
    "- Build an HMM profile using `hmmbuild`.\n",
    "- Filter sequences to avoid bias in evaluation.\n",
    "- Run `hmmsearch` on test sets.\n",
    "- Evaluate model performance with multiple thresholds.\n",
    "\n",
    "## Linux Command-Line Tools: Summary of Usage\n",
    "\n",
    "This section summarizes the most commonly used Linux shell commands in this notebook:\n",
    "\n",
    "- **`cat`**: Concatenates and displays the content of files.\n",
    "- **`awk`**: A powerful text-processing tool used for pattern scanning and field-based extraction.\n",
    "- **`grep`**: Searches for lines matching a pattern within a file.\n",
    "- **`cut`**: Extracts specific columns or fields from each line of a file.\n",
    "- **`sort`**: Sorts lines in a file, alphabetically or numerically.\n",
    "- **`comm`**: Compares two sorted files and shows common and distinct lines.\n",
    "- **`makeblastdb`**: Creates a searchable BLAST database from a FASTA file.\n",
    "- **`blastp`**: Compares protein sequences using BLAST against a protein database.\n",
    "- **`cd-hit`**: Clusters sequences to reduce redundancy based on sequence identity thresholds.\n",
    "- **`hmmbuild`**: Builds a profile Hidden Markov Model (HMM) from a multiple sequence alignment.\n",
    "- **`hmmsearch`**: Searches sequence databases for matches to a profile HMM.\n",
    "- **`head` / `tail`** – Outputs the first or last N lines of a file (useful for dataset splitting).\n",
    "- **`wc`** – Word count; used with `-l` to count lines (e.g., number of sequences).\n",
    "- **`less`** – Paginates the display of long files (useful for inspection)."
   ],
   "id": "a375b3be44f29249"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Extract Human and Non-Human Kunitz Sequences\n",
    "\n",
    "From the file `all_kunitz.fasta`, extract sequences annotated as \"Homo sapiens\" and separate them from non-human sequences."
   ],
   "id": "4009074662b605ae"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Estrai sequenze umane\n",
    "awk '/^>/ {f=($0 ~ /Homo sapiens/)} f' all_kunitz.fasta > human_kunitz.fasta\n",
    "\n",
    "# Estrai sequenze non umane\n",
    "grep -v \"Homo sapiens\" all_kunitz.fasta > nothuman_kunitz.fasta\n",
    "\n",
    "# Controllo del numero di sequenze umane (intestazioni)\n",
    "grep \"sp\" human_kunitz.fasta | wc -l\n"
   ],
   "id": "3d71cf243b0d840b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Extract PF00014 sequences from PDB report and cluster with CD-HIT\n",
    "\n",
    "Download a CSV from RCSB PDB filtered for:\n",
    "- PFAM = PF00014\n",
    "- Length 45–80 aa\n",
    "- Resolution ≤ 3.5 Å\n",
    "\n",
    "Then extract the sequences in FASTA and reduce redundancy using CD-HIT at 90%.\n"
   ],
   "id": "13f712670aa6fcc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Estrai sequenze PF00014 dal CSV\n",
    "cat rcsb_pdb_custom_report_20250410062557.csv | tr -d '\"' \\\n",
    "| awk -F ',' '{if (length($2)>0) {name=$2}; print name ,$3,$4,$5}' \\\n",
    "| grep PF00014 \\\n",
    "| awk '{print \">\"$1\"_\"$3; print $2}' > pdb_kunitz_customreported.fasta\n",
    "\n",
    "# Rimuovi ridondanza con CD-HIT (90%)\n",
    "cd-hit -i pdb_kunitz_customreported.fasta -o pdb_kunitz_customreported_nr.fasta -c 0.9\n"
   ],
   "id": "72a10a8a98788693"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Structural Alignment and HMM Building\n",
    "\n",
    "Use the representative sequences to submit to PDBeFold and download the `.ali` alignment. Reformat for `hmmbuild`, then build the structural HMM.\n"
   ],
   "id": "2fe533854c6a2c9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Riformattazione del file .ali in FASTA-like\n",
    "awk '{\n",
    "  if (substr($1,1,1)==\">\") {\n",
    "    print \"\\n\" toupper($1)\n",
    "  } else {\n",
    "    printf \"%s\", toupper($1)\n",
    "  }\n",
    "}' pdb_kunitz_rp.ali > pdb_kunitz_rp_formatted.ali\n",
    "\n",
    "# Costruzione dell'HMM\n",
    "hmmbuild structural_model.hmm pdb_kunitz_rp_formatted.ali\n"
   ],
   "id": "410a3d59b2a7065"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. BLAST Filtering to Remove Overlapping Sequences\n",
    "\n",
    "To avoid evaluating the same sequences used to build the model, we perform BLAST between the representative PDB Kunitz sequences and the full UniProt Kunitz set.\n",
    "\n",
    "We retain only sequences with identity < 95% and coverage < 50%.\n"
   ],
   "id": "b43fd2a525b3ca13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Crea il database BLAST da tutte le sequenze Kunitz (umane + non umane)\n",
    "makeblastdb -in all_kunitz.fasta -dbtype prot -out all_kunitz.fasta\n",
    "\n",
    "# Lancia BLAST\n",
    "blastp -query pdb_kunitz_rp.fasta -db all_kunitz.fasta -out pdb_kunitz_nr_23.blast -outfmt 7\n"
   ],
   "id": "ed7eb193800a9ff0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Estrai gli ID UniProt da escludere (identity ≥ 95% e coverage ≥ 50%)\n",
    "grep -v \"^#\" pdb_kunitz_nr_23.blast | awk '{if ($3>=95 && $4>=50) print $2}' | sort -u | cut -d \"|\" -f 2 > to_remove.ids\n",
    "\n",
    "# Estrai tutti gli ID delle sequenze Kunitz\n",
    "grep \">\" all_kunitz.fasta | cut -d \"|\" -f 2 > all_kunitz.id\n",
    "\n",
    "# Ottieni gli ID da mantenere\n",
    "comm -23 <(sort all_kunitz.id) <(sort to_remove.ids) > to_keep.ids\n"
   ],
   "id": "ff663a2ab1bfd6eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Estrai le sequenze finali da tenere (positivi validi per il test)\n",
    "python3 get_seq.py to_keep.ids all_kunitz.fasta ok_kunitz.fasta\n"
   ],
   "id": "4e1feba3267d30dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\n",
   "id": "89a3fb92d93d454b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Construction of the Negative Dataset\n",
    "\n",
    "Extract from SwissProt all proteins that do NOT contain the Kunitz domain and create the negative FASTA dataset.\n"
   ],
   "id": "b09a1011484fc0a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ottieni tutti gli ID da SwissProt\n",
    "grep \">\" uniprot_sprot.fasta | cut -d \"|\" -f 2 > sp.id\n",
    "\n",
    "# Escludi gli ID che appartengono a sequenze Kunitz\n",
    "comm -23 <(sort sp.id) <(sort all_kunitz.id) > sp_negs.ids\n",
    "\n",
    "# Estrai le sequenze negative finali\n",
    "python3 get_seq.py sp_negs.ids uniprot_sprot.fasta sp_negs.fasta\n"
   ],
   "id": "39aadc20fcf66053"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "40fe1a66db9c391d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Train/Test Set Construction\n",
    "\n",
    "Split the positive and negative datasets into training and testing halves using randomization.\n"
   ],
   "id": "7c21d52e94c3a1e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Randomizza gli ID\n",
    "sort -R to_keep.ids > random_ok_kunitz.ids\n",
    "sort -R sp_negs.ids > random_sp_negs.ids\n",
    "\n",
    "# Dividi in due metà\n",
    "head -n 183 random_ok_kunitz.ids > pos_1.ids\n",
    "tail -n 183 random_ok_kunitz.ids > pos_2.ids\n",
    "\n",
    "head -n 286417 random_sp_negs.ids > neg_1.ids\n",
    "tail -n 286417 random_sp_negs.ids > neg_2.ids\n"
   ],
   "id": "b969ed1425fe62d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Estrai i FASTA dei 4 set\n",
    "python3 get_seq.py pos_1.ids uniprot_sprot.fasta > pos_1.fasta\n",
    "python3 get_seq.py pos_2.ids uniprot_sprot.fasta > pos_2.fasta\n",
    "python3 get_seq.py neg_1.ids uniprot_sprot.fasta > neg_1.fasta\n",
    "python3 get_seq.py neg_2.ids uniprot_sprot.fasta > neg_2.fasta\n"
   ],
   "id": "4ee19936828ff7ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. HMMER Search and .class File Generation\n",
    "\n",
    "We run `hmmsearch` on each of the four FASTA sets (pos_1, pos_2, neg_1, neg_2) using the trained HMM.  \n",
    "To ensure consistency in e-value calculation across datasets of different sizes, we use the `-Z 1000` option.  \n",
    "We convert the output to `.class` format to later evaluate classification performance.\n"
   ],
   "id": "fd467523e0036724"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Esegui hmmsearch con tabular output per ogni set\n",
    "hmmsearch -Z 1000 --max --tblout pos_1.out structural_model.hmm pos_1.fasta\n",
    "hmmsearch -Z 1000 --max --tblout pos_2.out structural_model.hmm pos_2.fasta\n",
    "hmmsearch -Z 1000 --max --tblout neg_1.out structural_model.hmm neg_1.fasta\n",
    "hmmsearch -Z 1000 --max --tblout neg_2.out structural_model.hmm neg_2.fasta\n"
   ],
   "id": "16f2d24c624a7670"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We now extract useful information from the HMMER output:\n",
    "- Identifier\n",
    "- True label (1 for positive, 0 for negative)\n",
    "- Full-sequence E-value\n",
    "- Domain E-value (if available)\n",
    "\n",
    "These are stored in `.class` files to be used with the `performance.py` script.\n"
   ],
   "id": "772b612d5aa96c08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# POSITIVI\n",
    "grep -v \"^#\" pos_1.out | awk '{split($1,a,\"|\"); print a[2]\"\\t1\\t\"$5\"\\t\"$8}' > pos_1.class\n",
    "grep -v \"^#\" pos_2.out | awk '{split($1,a,\"|\"); print a[2]\"\\t1\\t\"$5\"\\t\"$8}' > pos_2.class\n",
    "\n",
    "# NEGATIVI\n",
    "grep -v \"^#\" neg_1.out | awk '{split($1,a,\"|\"); print a[2]\"\\t0\\t\"$5\"\\t\"$8}' > neg_1.class\n",
    "grep -v \"^#\" neg_2.out | awk '{split($1,a,\"|\"); print a[2]\"\\t0\\t\"$5\"\\t\"$8}' > neg_2.class\n"
   ],
   "id": "c5fd8bc1ca8a08c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If `hmmsearch` does not report a match, that sequence is still part of the dataset and should be considered a true negative.  \n",
    "We assign them a default E-value of 10.0 and append them to the `.class` files using `comm`.\n"
   ],
   "id": "6b64e13b4c63795a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# NEGATIVI NON MATCHATI: li aggiungiamo con E-value 10.0\n",
    "comm -23 <(sort neg_1.ids) <(cut -f1 neg_1.class | sort) | awk '{print $1\"\\t0\\t10.0\\t10.0\"}' >> neg_1_hits.class\n",
    "comm -23 <(sort neg_2.ids) <(cut -f1 neg_2.class | sort) | awk '{print $1\"\\t0\\t10.0\\t10.0\"}' >> neg_2_hits.class\n"
   ],
   "id": "97203b83152c73ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9. Evaluate Model Performance with Different E-value Thresholds\n",
    "\n",
    "We now merge the positive and negative `.class` files into two evaluation sets (`set_1` and `set_2`) and use the script `performance.py` to compute evaluation metrics such as:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- MCC (Matthews Correlation Coefficient)\n",
    "\n",
    "We repeat the evaluation at multiple E-value thresholds (e.g., 1e-3 to 1e-10) to identify the optimal decision boundary.\n"
   ],
   "id": "920f4083838ec36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Unione dei set\n",
    "cat pos_1.class neg_1_hits.class > set_1.class\n",
    "cat pos_2.class neg_2_hits.class > set_2.class\n"
   ],
   "id": "fd8d106262a65bc9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 10. Evaluate Model Performance at Different Thresholds and Analyze Errors\n",
    "\n",
    "In this step, we evaluate model performance at different E-value thresholds using `performance.py`. The goal is to identify the optimal threshold based on the **Matthews Correlation Coefficient (MCC)**.\n",
    "\n",
    "We also analyze false negatives—true positive sequences with high E-values that were misclassified as negatives. This helps us identify potential sensitivity issues in the model.\n",
    "\n",
    "- Run performance evaluation for both `set_1.class` and `set_2.class` at a fixed threshold (`1e-5`)\n",
    "- Repeat evaluation across multiple thresholds (from `1e-1` to `1e-10`)\n",
    "- Sort results based on MCC to find the best cutoff\n",
    "- Extract and save the worst false negatives for comparison and further inspection\n"
   ],
   "id": "e132eb1ee99b7ebb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Calcola performance su soglia fissa\n",
    "python3 performance.py set_1.class 1e-5\n",
    "python3 performance.py set_2.class 1e-5\n",
    "\n",
    "# Ripeti per diversi e-value per trovare la soglia ottimale (in base a MCC)\n",
    "for i in $(seq 1 10); do\n",
    "  python3 performance.py set_1.class 1e-$i\n",
    "done | sort -nrk 6  # Ordina in base alla sesta colonna (MCC)\n",
    "\n",
    "# Analisi errori – Trova falsi negativi con E-value alti\n",
    "sort -grk 3 pos_1.class | less\n",
    "\n",
    "# Estrai i peggiori falsi negativi in file separati per confronto\n",
    "awk '$2 == 1 && $3 > 1e-5' pos_1.class | sort -grk 3 > fn_pos1.txt\n",
    "awk '$2 == 1 && $3 > 1e-5' pos_2.class | sort -grk 3 > fn_pos2.txt"
   ],
   "id": "22400757f6562c25"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "41d6af6d559ca8c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\n",
   "id": "be83807ae844c181"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
